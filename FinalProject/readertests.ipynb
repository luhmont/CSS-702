{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spark-nlp NOT USED\n",
    "#pip install pyspark NOT USED\n",
    "\n",
    "\n",
    "#pip install --upgrade pymupdf\n",
    "#pip install -U sentence-transformers\n",
    "\n",
    "import pymupdf #for reading pdf files\n",
    "from sentence_transformers import SentenceTransformer #for getting vectors from text\n",
    "from pathlib import Path #for reading all pdfs in the folder\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "restaurantdf = pd.DataFrame(columns=[\"Restaurant Name\", \"Keywords\", \"Embeddings\"])\n",
    "\n",
    "def pdf_reader(file_path): #test method for reading pdfs\n",
    "    #open file\n",
    "    file = pymupdf.open(file_path)\n",
    "    \n",
    "    #read the file\n",
    "    #out = open(\"output.txt\", \"wb\") #prints text to output file in the directory\n",
    "    out = \"\"\n",
    "    for page in file: #iterate the pages\n",
    "        text = page.get_text() #get plain text\n",
    "        out += text #write text of page\n",
    "    #print(out)\n",
    "        \n",
    "    file.close()\n",
    "    return out\n",
    "\n",
    "def txt_reader(): #test method for reading text files\n",
    "    #open file\n",
    "    file = open(\"testerfile.txt\")\n",
    "    \n",
    "    #read the file\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "    \n",
    "    #close the file\n",
    "    file.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #doc = pymupdf.open(\"\")\n",
    "    #txt_reader()\n",
    "    #print(pdf_reader(\"Merged March 2023 (wine).pdf\"))\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentence1 = \"The weather is lovely today.\"\n",
    "sentence2 = \"It's so sunny outside!\"\n",
    "sentence3 = \"He drove to the stadium.\"\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    sentence1,\n",
    "    sentence2,\n",
    "    sentence3,\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "#embedding1 = embeddings[0] #print the embedding for sentence1 in the index 0\n",
    "#print(embedding1)\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 384)\n",
      "[0.33162087202072144, 0.37901878356933594, 0.07464508712291718]\n"
     ]
    }
   ],
   "source": [
    "#logic for ingesting the menus and adding them to a vector space\n",
    "\n",
    "# returns all file paths that has .pdf as extension in the specified directory, from https://stackoverflow.com/questions/70848337/how-to-read-multiple-pdf-from-a-folder-one-by-one\n",
    "pdf_search = Path(str(Path.cwd())).rglob(\"*.pdf\") #gets all the pdf files in the current directory\n",
    "pdf_files = [str(file.absolute()) for file in pdf_search] #iterates over all the pdf files in the current directory and adds them to an array.\n",
    "\n",
    "pdf_filecontent = [pdf_reader(file) for file in pdf_files] #take the file names and extract the text content from them.\n",
    "\n",
    "menuembeddings = model.encode(pdf_filecontent)\n",
    "print(menuembeddings.shape)\n",
    "menuembedding1 = menuembeddings[2] #using the wine restuarant to tests similarity scores\n",
    "\n",
    "\n",
    "prompt0 = \"I like wine and different alcoholic drinks like pinot and red wine, cabernet sauvignon, rose wine, and sauvignon blanc, any wine or beer is good.\"\n",
    "prompt1 = \"I want to eat cheeseburgers and sandwiches, they're some of my favorite foods to eat.\"\n",
    "prompt2 = \"The Dodgers are the best baseball team to ever exist, I like to watch their games on sundays.\"\n",
    "prompts = [prompt0, prompt1, prompt2]\n",
    "promptembeddings = model.encode(prompts)\n",
    "\n",
    "similarities = []\n",
    "for i, embedding in enumerate(promptembeddings):\n",
    "    similarity = model.similarity(embedding, menuembedding1) #compare each prompt in the prompt array to the wine restuarant.\n",
    "    similarities.append(similarity.item()) #append the similarity score to the array in a scalar format\n",
    "    \n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 384)\n",
      "[0.33162087202072144, 0.37901878356933594, 0.07464508712291718]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# returns all file paths that has .pdf as extension in the specified directory, from https://stackoverflow.com/questions/70848337/how-to-read-multiple-pdf-from-a-folder-one-by-one\n",
    "pdf_search = Path(str(Path.cwd())).rglob(\"*.pdf\") #gets all the pdf files in the current directory\n",
    "pdf_files = [str(file.absolute()) for file in pdf_search] #iterates over all the pdf files in the current directory and adds them to an array.\n",
    "\n",
    "pdf_filecontent = [pdf_reader(file) for file in pdf_files] #take the file names and extract the text content from them.\n",
    "\n",
    "menuembeddings = model.encode(pdf_filecontent)\n",
    "print(menuembeddings.shape)\n",
    "menuembedding1 = menuembeddings[2] #using the wine restuarant to tests similarity scores\n",
    "\n",
    "\n",
    "prompt0 = \"I like wine and different alcoholic drinks like pinot and red wine, cabernet sauvignon, rose wine, and sauvignon blanc, any wine or beer is good.\"\n",
    "prompt1 = \"I want to eat cheeseburgers and sandwiches, they're some of my favorite foods to eat.\"\n",
    "prompt2 = \"the Dodgers are the best baseball team to ever exist, I like to watch their games on sundays.\"\n",
    "prompts = [prompt0, prompt1, prompt2]\n",
    "promptembeddings = model.encode(prompts)\n",
    "\n",
    "similarities = []\n",
    "for i, embedding in enumerate(promptembeddings):\n",
    "    similarity = model.similarity(embedding, menuembedding1) #compare each prompt in the prompt array to the wine restuarant.\n",
    "    similarities.append(similarity.item()) #append the similarity score to the array in a scalar format\n",
    "    \n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st.title(\"Restuarant Query Bot\") #page title\\n    with st.chat_message(\"assistant\"): #gives name to bot and writes welcome message\\n        st.write(\"Hello, I\\'m your restuarant assistant, how can I help you?\")\\n        \\n    if \"messages\" not in st.session_state: #if no messages have been sent then initialize chat history\\n        st.session_state.messages = [] #variable for chat history\\n        \\n    for message in st.session_state.messages: #loop that iterates through the chat history to display the history in the message container.\\n        with st.chat_message(message[\"role\"]):\\n            st.markdown(message[\"content\"])\\n    \\n    if prompt := st.chat_input(\"Say something\"):\\n        st.chat_message(\"user\").markdown(prompt) #display message in chat message container\\n        st.session_state.messages.append({\"role\":\"user\", \"content\": prompt}) #add message to chat history\\n        \\n        response = f\"{prompt}\"\\n        with st.chat_message(\"assistant\"):\\n            st.markdown(response)\\n            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\\n    return'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#echo bot code\n",
    "\n",
    "\"\"\"st.title(\"Restuarant Query Bot\") #page title\n",
    "    with st.chat_message(\"assistant\"): #gives name to bot and writes welcome message\n",
    "        st.write(\"Hello, I'm your restuarant assistant, how can I help you?\")\n",
    "        \n",
    "    if \"messages\" not in st.session_state: #if no messages have been sent then initialize chat history\n",
    "        st.session_state.messages = [] #variable for chat history\n",
    "        \n",
    "    for message in st.session_state.messages: #loop that iterates through the chat history to display the history in the message container.\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    if prompt := st.chat_input(\"Say something\"):\n",
    "        st.chat_message(\"user\").markdown(prompt) #display message in chat message container\n",
    "        st.session_state.messages.append({\"role\":\"user\", \"content\": prompt}) #add message to chat history\n",
    "        \n",
    "        response = f\"{prompt}\"\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.markdown(response)\n",
    "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    return\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword\n",
      "performance\n",
      "prediction\n",
      "standard\n",
      "rouge\n",
      "learning\n",
      "partial\n",
      "perfect\n",
      "accuracy\n",
      "machine\n"
     ]
    }
   ],
   "source": [
    "restuarantdf = pd.DataFrame([\"Restuarant Name\", \"Keywords\", \"Embeddings\"])\n",
    "\n",
    "def restuarant_datapull(text): #uses spaCy to extract restuarant keywords, and add the title, keywords, and embeddings to a data frame.\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] #three labels for the types of extracted words\n",
    "    doc = nlp(text.lower()) #lowercase all words\n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation): #if word is in the stop words or is punctuation move on\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag): #if not add to keywords\n",
    "            result.append(token.text)\n",
    "    return result\n",
    "\n",
    "new_text = \"\"\"\n",
    "When it comes to evaluating the performance of keyword extractors, you can use some of the standard metrics in machine learning: accuracy, precision, recall, and F1 score. However, these metrics donâ€™t reflect partial matches. they only consider the perfect match between an extracted segment and the correct prediction for that tag.\n",
    "Fortunately, there are some other metrics capable of capturing partial matches. An example of this is ROUGE.\n",
    "\"\"\"\n",
    "output = set(restuarant_datapull(new_text))\n",
    "most_common = Counter(output).most_common(10)\n",
    "for item in most_common:\n",
    "    print(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restuarant_info():\n",
    "    restaurantdf\n",
    "    restaurant_titles = get_restaurantnames()\n",
    "    restaurant_texts = get_restauranttext()\n",
    "    \n",
    "    for name, text in zip(restaurant_titles, restaurant_texts):\n",
    "        keywords = restaurant_datapull(text)\n",
    "        embeddings = get_embeddings(keywords)\n",
    "        restaurantdf.loc[len(restaurantdf)] = [name, keywords, embeddings]\n",
    "    return restaurantdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
